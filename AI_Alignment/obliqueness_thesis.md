# Not Orthogonal and Not Diagonal, but Oblique

What is left from a rejection of both the Orthogonality thesis and the Diagonality thesis? Jessica argues for an in-between of sorts in the Obliqueness thesis[^1]. The Orthogonality thesis roughly states that there is no correlation between degrees of intelligence and what values the intelligent entity holds. Conversely, the Diagonality thesis states that in the limit of (super)intelligence, all entities converge upon the same set of values. In rejecting both theses, Jessica introduces an Obliqueness thesis which states that the degree of intelligence consists in some relation to the set of values an entity has.

I wonder if a simpler presentation of the author’s main thesis will be helpful in elucidating its key implications and suggestions for further exploration. Roughly, I take it that in arguing for the Obliqueness thesis:

- **P1**) Some beliefs are inaccessible (or tends to be unavailable) to entities below a certain threshold of intelligence (*argument from bayes/VNM*)
- **P2**) More capable intelligences tend to adopt beliefs that more accurately reflect reality (*argument from ontological change*)
- **P1 + P2 = SC1**) The beliefs of an entity depends on its level of intelligence
- **P3**) Values are sensitive to beliefs an entity holds (*argument from value-relevant symmetries / argument from brain messiness*)
- **C**) Values are sensitive to the level of intelligence of an entity

The above formulation more formally ties together the various piecemeal arguments made throughout Jessica’s essay into a cogent argument for some correlation between the degree of an entity’s intelligence and the values that it holds.

Most of the force of this argument rests on establishing some correlation in **SC1** between beliefs (or some other form of intelligent-related capacity) to a system’s degree of intelligence, and further, **P3** that they matter for value formation. Here, Orthogonality thesis can be taken to accept **P3** but reject **SC1**. And the Diagonality thesis may either provide a strong **SC1** claim (that belief converges) or stronger **P3** claim (that values converge on beliefs) and subsequently strengthen **C** into the convergence relation.

One could also argue about whether **P1** *AND* **P2** are necessary to yield **SC1** (note that one moves in the direction of ‘lower’ intelligence and the other to ‘higher’ intelligence), and whether **P2** relies on some commonly accessible realism that is merely a function of the degree of intelligence. Furthermore, insofar as realism is a metaphysical view that us feeble human minds have come up with, aren’t there reasons to believe that more capable intelligences may have distinct metaphysics that transcends or is incompatible with realism?

Value ethics or deontology attacks **P3** in some sense with a strict normative preference for duty or obligations not contingent upon beliefs. It does not matter what you believe, one should act in a way which fulfils one's obligations and duties. However, perhaps this attack is somewhat weakened by the possibility of different obligations and duties being available to the entity.

One last point on the soundness of the above argument, “belief” in **P1**, **P2**, and **SC1** could also be substituted for something else upon which values rests on (via some **P3** alternative) and is not entirely uncorrelated with intelligence. Such a substitution will still work within the structure of this argument thus presented. A hint of this is in Jessica’s argument from brain messiness which targets human cognitive faculties of language and evolutionary history.

Now let’s turn to the implications of this view and how it differs from the theses which Jessica rejects. The Orthogonality thesis is much too pessimistic in the sense that nothing about values could be dependent upon investigating or constraining the degree to which our systems are intelligent (i.e. a less capable LLM today could still be paperclip optimizing in the sense of having widely mis-aligned values). Whereas the Diagonality thesis is much too optimistic in the sense that we hope that the convergence results in some good set of values (to humans too). The Obliqueness thesis presents an alternative that suggests further empirical study into the relation in **SC1** and **P3**: how beliefs may be constrained by the level of intelligence, and how values may differ given different levels of intelligence. Ultimately, Obliqueness leaves open the hope that *some* degree of information overlap exists between looking at the degree to which an entity is intelligent and the set of values that it adopts.

[^1]: https://www.lesswrong.com/posts/vdATCfuxdtdqM2wh9/the-obliqueness-thesis
