Joe Carlsmith reminds us that in the messy nature of reality, we humans are yet still participants in shaping our future trajectory. Within his article “Loving A World You Don’t Trust” is a message to reject powerless pessimism and avoid a binary view of nature as good/bad. At the end of his essay series, Carlsmith projects optimism and urges pragmatism in response to the potentiality of AGI being an alien “Other”.

The idea of an “Otherness” as introduced by Calsmith in “Gentleness and the artificial Other” is described as an unbridgeable gulf in capability, experience, and values. Likened to that of two species meeting for the first time, like our imagined Sci-Fi encounters in Contact (1997 film, Robert Zemeckis), Arrival (2016, film, Denis Villeneuve), and likely the kind of unfathomable aliens at the end of 2001: A Space Odyssey (1968, film, Stanley Kubrick).

Our history of colonialism has not been kind to encounters of different human social groups with differences in these traits. That motivates an extension of this pessimism to interspecies interactions with a potentially vastly larger magnitude of such differences. Placed in competition, and assuming AGIs have better capabilities, it is conceivable that humanity be relegated to footnotes of history as a primordial ancestor in the vast timescale of evolution.

Are there good reasons to believe that such will be the case for AGI? In an essay titled “Conscious exotica”, Murray Shanahan draws upon Thomas Nagel’s thought experiment “What is it like to be a bat?” to motivate the notion that the space of possible consciousnesses is vast, and large portions of them inaccessible to us. Assuming that we draw upon this distribution of all possible consciousness, all possible thinking feeling beings, the likelihood we get within the vicinity of human understanding is abysmally small.

Why does this matter? Consider the short-story “They're Made Out of Meat” by Terry Bisson, in it alien explorers arrive on Earth, and to their dismay discover the radio signals they’ve received are merely “flapping of meat”. Unimpressed, they simply depart and mark our sector of the galaxy as ‘uninhabited’. Contrast this and the assistants in the film Her to that of Ava in Ex Machina, or the alien squid-like creatures in Arrival. I would fear the former cases of alien interaction more than the latter, at least in the latter examples, an intent to communicate is present.

The German biologist Jakob von Uexküll introduced the term Umwelt as the subjective environment wherein organisms engage in and Merkwelt as the particular physical sensory boundaries of a particular organism. In the case of alien AGI, the fear is that their Umwelten will be vastly different from humans. Umwelt may be subjective, but Merkwelt is something with which interventions could be made upon. In convergent evolution, different biological lifeforms have evolved similar sensory apparatus because of the physical constraints in environments that they interact with. To be able to communicate, the idea here is that some overlap in Merkwelt needs to be present, some channel of information flow that is accessible and important to both parties.

So just what are the environments wherein AI systems interact in today? Why do we wish for AGI systems? I believe it is pertinent that we investigate and clarify the intent of such developments and as much as possible, bring such systems within the space of intersecting Merkwelt as humans. Carlsmith rightly points out the orthorgonality between capability, sentience, and benevolence, although there is no reason for believing that goodness naturally comes out of increased capabilities, neither is there strong reasons to believe in the flip-side. The “wisdom comes in the case-by-case” as Carlsmith puts it, just what do we wish for in our dreams of AGI? I suspect a deeper investigation into this direction will yield insights as to how such systems may be placed in environments wherein a convergent development of goals and values between AGI and humans can exist.
