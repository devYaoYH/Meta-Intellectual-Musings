# SB-1047 vs EU AI Act - two approaches to AI regulation

In California governor Newsom’s rejection of SB-1047, he cites a lack of specific “demonstrable risks” to constrain the set of ‘covered models’. SB-1047 would have enabled a broad swath of current foundational model development to fall under the notion of ‘covered models’ based on their immense resource requirements, *irrespective of their application contexts*. This is in stark contrast to the EU AI Act which explicitly applies to “high-risk AI systems” according to a graded scale of risk assessment (unacceptable, high-risk, limited-risk, minimal-risk)[^1].

I think the two pieces of legislation differ primarily in their targeting of different risks of AI systems. Where the EU AI Act targets somewhat predictable and foreseen risks of deploying AIs within certain applications, SB-1047 attempts to preempt and mitigate unforeseen risks of developing those AI models in the first place.

[^1]: https://www.wilmerhale.com/en/insights/blogs/wilmerhale-privacy-and-cybersecurity-law/20240717-what-are-highrisk-ai-systems-within-the-meaning-of-the-eus-ai-act-and-what-requirements-apply-to-them
